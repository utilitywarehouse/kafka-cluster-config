#!/usr/bin/env bash
#
# This script generates a Terraform S3 bucket lifecycle configuration for MSK
# topic backups based on the retention settings defined in Kafka topic
# resource files.
#
# Usage: ./your_script_name.sh <dev|prod> [--diff]

# --- START PRE-FLIGHT CHECKS ---
# Exit immediately if a command exits with a non-zero status.
set -e
# Treat unset variables as an error when substituting.
set -u
# Pipelines return the exit status of the last command to exit with a non-zero status.
set -o pipefail

# --- GLOBAL SETUP ---
# Determine the absolute path of the directory where the script is located.
readonly SCRIPT_DIR=$( cd -- "$( dirname -- "${BASH_SOURCE[0]}" )" &> /dev/null && pwd )

# Create a temporary file and set a trap to clean it up on script exit.
TMP_FILE=$(mktemp)
trap 'rm -f -- "$TMP_FILE"' EXIT

# --- FUNCTION DEFINITIONS ---

##
# Finds all kafka topic resources, extracts retention data, sorts it,
# and saves it to a temporary file.
# Globals:
#   TMP_FILE
# Arguments:
#   $1: The root directory to search for Terraform files.
##
extract_topic_retention_data() {
  local root_cluster="$1"

  # Find, extract, and sort the data before writing it to the temp file.
  # Use LC_ALL=C to ensure a consistent, portable sort order across systems.
  find "${root_cluster}" -name "*.tf" -print0 | xargs -0 awk '
    BEGIN {
      total_resources=0
      infinite_topics=0
      no_retention_topics=0
      empty_name_topics=0
    }
    /resource "kafka_topic"/ {
      in_resource=1
      topic=""
      retention_ms=""
      resource_name=$3
      gsub(/"/,"",resource_name)
    }
    in_resource && /name[ ]*=/ {
      topic=$3
      gsub(/"/,"",topic)
    }
    in_resource && /"retention.ms"/ {
      retention_ms=$3
      gsub(/[^0-9-]/,"",retention_ms)
    }
    in_resource && /^}/ {
      # Process at end of resource block
      total_resources++
      if(topic == "") {
        empty_name_topics++
        print "WARNING: Empty topic name for resource: " resource_name > "/dev/stderr"
      }
      if(retention_ms == "") {
        no_retention_topics++
      } else if(retention_ms+0 <= 0) {
        infinite_topics++
      } else {
        # Valid retention with positive value
        d=int(retention_ms/86400000) + 1
        if(topic!="") {
          print topic "=" d
        }
      }
      in_resource=0
      topic=""
      retention_ms=""
    }
    END {
      print "\n=== Statistics ===" > "/dev/stderr"
      print "Total kafka_topic resources found: " total_resources > "/dev/stderr"
      print "Topics with infinite retention (retention.ms <= 0): " infinite_topics > "/dev/stderr"
      print "Topics without retention.ms (compacted topics): " no_retention_topics > "/dev/stderr"
      print "Topics with empty name: " empty_name_topics > "/dev/stderr"
      print "Topics with associated bucket rules: " (total_resources - infinite_topics - no_retention_topics) > "/dev/stderr"
    }
  ' | LC_ALL=C sort > "$TMP_FILE"
}

##
# Writes the static Terraform header to the output file.
# Arguments:
#   $1: The output file path.
#   $2: The environment name (e.g., "dev" or "prod").
##
output_header() {
  local output_file="$1"
  local env="$2"

  cat << EOF > "$output_file"
#################################
# DO NOT update this file manually, it is autogenerated
#################################

resource "aws_s3_bucket_lifecycle_configuration" "msk_topics_retention" {
  bucket = "uw-${env}-pubsub-msk-backup"

  rule {
    id     = "default-to-intelligent-tiering"
    status = "Enabled"
    filter {}
    transition {
      days          = 0
      storage_class = "INTELLIGENT_TIERING"
    }
  }

EOF
}

##
# Generates and appends Terraform rules to the output file from pre-sorted data.
# Globals:
#   TMP_FILE
# Arguments:
#   $1: The output file path.
#   $2: The S3 prefix for the backup files.
##
output_rules() {
  local output_file="$1"
  local s3_prefix="$2"

  # Append rules by processing the pre-sorted temp file line-by-line.
  awk -F= -v s3_prefix="$s3_prefix" '
  {
    topic=$1
    days=$2
    s3_path=topic;
    printf "  rule {\n"
    printf "    id     = \"%s\"\n", topic
    printf "    status = \"Enabled\"\n"
    printf "    expiration { days = %d }\n", days
    printf "    filter { prefix = \"%s/%s/\" }\n", s3_prefix, s3_path
    printf "  }\n\n"
  }
  ' "$TMP_FILE" >> "$output_file"

  # Append the final closing brace.
  echo "}" >> "$output_file"
}

# --- MAIN LOGIC ---
main() {
  local env="$1"
  local diff_mode="$2"
  local root_cluster="${SCRIPT_DIR}/../${env}-aws/kafka-shared-msk"
  local s3_prefix="msk-backup-parquet"
  local output_dir="${root_cluster}/msk-backup-bucket-retention"
  local original_file="${output_dir}/generated-retention.tf"
  local temp_file="${original_file}.tmp"

  # Decide the output file based on whether --diff was passed
  local output_file
  if [[ "$diff_mode" == "true" ]]; then
    output_file="$temp_file"
  else
    output_file="$original_file"
  fi

  # Step 1: Extract and sort data into a temporary file.
  extract_topic_retention_data "$root_cluster"

  # Step 2: Generate the Terraform configuration file.
  mkdir -p "$output_dir"
  output_header "$output_file" "$env"
  output_rules "$output_file" "$s3_prefix"

  # Step 3: If in diff mode, compare files. Otherwise, confirm generation.
  if [[ "$diff_mode" == "true" ]]; then
    # Check if original file exists to diff against.
    if [[ ! -f "$original_file" ]]; then
      echo "Error: Original file '$original_file' not found for comparison." >&2
      echo "Generated content is in '$temp_file'." >&2
      exit 1
    fi

    # Compare the files and capture the output. The `|| true` prevents `set -e`
    # from exiting if `diff` finds differences (which returns exit code 1).
    diff_output=$(diff -u "$original_file" "$temp_file" || true)
    rm -f "$temp_file" # Clean up the temporary file

    if [[ -n "$diff_output" ]]; then
      # The '%s\n' format string prints each subsequent argument on a new line.
      # This is a highly portable and safe way to print multi-line messages.
      (
        printf '%s\n' \
          "----------------------------------------------------------------------" \
          "FAILURE REASON: The generated file $original_file must be updated." \
          "HOW TO FIX: Run \`make generate\` and commit the changed generated files" \
          "----------------------------------------------------------------------" \
          "--- DETECTED DRIFT ---" \
          "$diff_output"
      ) >&2
      exit 1
    else
      echo "âœ… No configuration changes detected. Files are up-to-date."
    fi
  else
    echo "Generated: $output_file"
  fi
}

# --- SCRIPT EXECUTION ---
# Initialize variables for argument parsing
env=""
diff_mode="false"

# Parse arguments. This allows the optional flag to be in any position.
for arg in "$@"; do
  case $arg in
    dev|prod)
      if [[ -n "$env" ]]; then
        echo "Error: Environment specified more than once. Use either 'dev' or 'prod'." >&2
        exit 1
      fi
      env="$arg"
      ;;
    --diff)
      diff_mode="true"
      ;;
    *)
      echo "Error: Unrecognized argument '$arg'" >&2
      echo "Usage: $0 <dev|prod> [--diff]" >&2
      exit 1
      ;;
  esac
done

# Validate that the required environment argument was provided.
if [[ -z "$env" ]]; then
  echo "Usage: $0 <dev|prod> [--diff]" >&2
  echo "Error: Please provide a single environment argument: 'dev' or 'prod'." >&2
  exit 1
fi

# Run the main function with the parsed arguments.
main "$env" "$diff_mode"
